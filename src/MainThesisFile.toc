\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {1\hskip 2em}\uppercase {Introduction}}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1} Outline}{4}{section.1.1}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {2\hskip 2em}\uppercase {Background}}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1} Game Theory}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1} Problem Representations}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2} Solution Concepts}{7}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2} Reinforcement Learning}{8}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1} Tabular methods}{9}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2} Approximate Value-based methods}{10}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3} Policy Gradient methods}{11}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3} Multi-agent Reinforcement Learning (MARL)}{11}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1} Challenges in MARL}{12}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2} Methods in MARL}{12}{subsection.2.3.2}%
\contentsline {section}{\numberline {2.4} Online Convex Optimization and Mirror Descent}{12}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1} FoReL}{14}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2} Gradient Descent}{15}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3} Hedge}{16}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4} Mirror Descent}{17}{subsection.2.4.4}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {3\hskip 2em}\uppercase {Mirror Descent in Reinforcement Learning}}{18}{chapter.3}%
\contentsline {section}{\numberline {3.1} SPG}{18}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1} Trust-region methods}{20}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2} MDPO}{20}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1} Tabular MDPO}{22}{subsection.3.2.1}%
\contentsline {section}{\numberline {3.3} MMD}{23}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1} Connection between Variational Inequalities and QREs}{23}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2} MMD Algorithm}{25}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3} Behavioral form MMD}{26}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4} Closed-form vs Behavioral-form}{27}{subsection.3.3.4}%
\contentsline {subsection}{\numberline {3.3.5} Comparison of MMD to other Mirror Decent based methods}{28}{subsection.3.3.5}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {4\hskip 2em}\uppercase {Modified Updates for Last-iterate Convergence}}{29}{chapter.4}%
\contentsline {section}{\numberline {4.1} Neural Replicator Dynamics (NeuRD)}{30}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1} Replicator Dynamics and No-regret Learning}{30}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2} NeuRD}{31}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3} Relation to Natural Policy Gradients}{32}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4} Alternating vs Simultaneous gradient updates}{32}{subsection.4.1.4}%
\contentsline {section}{\numberline {4.2} Extragradient and Optimistic Gradient}{33}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1} Extragradient (EG)}{33}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2} Optimistic gradient (OPT)}{35}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3} Optimistic Mirror Descent}{35}{subsection.4.2.3}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {5\hskip 2em}\uppercase {Tabular Experiments}}{38}{chapter.5}%
\contentsline {section}{\numberline {5.1} Experimental Domains}{38}{section.5.1}%
\contentsline {section}{\numberline {5.2} Evaluation Metrics}{39}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1} Divergence to the equilibrium}{40}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2} Exploitability}{40}{subsection.5.2.2}%
\contentsline {section}{\numberline {5.3} Experiment Setup}{40}{section.5.3}%
\contentsline {section}{\numberline {5.4} Results}{41}{section.5.4}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {6\hskip 2em}\uppercase {Deep Multi-Agent RL Experiments}}{46}{chapter.6}%
\contentsline {section}{\numberline {6.1} Experimental Domains}{46}{section.6.1}%
\contentsline {section}{\numberline {6.2} Evaluation Metrics}{47}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1} Approximate Exploitability}{47}{subsection.6.2.1}%
\contentsline {section}{\numberline {6.3} Experiment Setup}{47}{section.6.3}%
\contentsline {section}{\numberline {6.4} Results}{48}{section.6.4}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {7\hskip 2em}\uppercase {Discussion}}{51}{chapter.7}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {8\hskip 2em}\uppercase {Conclusion}}{53}{chapter.8}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {\ }APPENDICES}{54}{chapter.8}%
\contentsline {chapter}{\xnumberline {\ }\ \ \ \ \ Appendix A}{55}{appendix.A}%
\contentsline {chapter}{\xnumberline {\ }\ \ \ \ \ Appendix B}{56}{appendix.B}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {\ }CITED LITERATURE}{57}{appendix.B}%

\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {1\hskip 2em}\uppercase {Introduction}}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1} Outline}{4}{section.1.1}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {2\hskip 2em}\uppercase {Background}}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1} Game Theory}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1} Problem Representations}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2} Solution Concepts}{7}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2} Reinforcement Learning}{8}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1} Tabular methods}{9}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2} Approximate Value-based methods}{10}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3} Policy Gradient methods}{11}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3} Multi-agent Reinforcement Learning (MARL)}{11}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1} Challenges in MARL}{12}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2} Methods in MARL}{12}{subsection.2.3.2}%
\contentsline {section}{\numberline {2.4} Online Convex Optimization and Mirror Descent}{12}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1} FoReL}{14}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2} Gradient Descent}{15}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3} Hedge}{16}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4} Mirror Descent}{17}{subsection.2.4.4}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {3\hskip 2em}\uppercase {Mirror Descent in Reinforcement Learning}}{18}{chapter.3}%
\contentsline {section}{\numberline {3.1} SPG}{18}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1} Trust-region methods}{20}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2} MDPO}{20}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1} Tabular MDPO}{21}{subsection.3.2.1}%
\contentsline {section}{\numberline {3.3} MMD}{22}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1} Connection between Variational Inequalities and QREs}{22}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2} MMD Algorithm}{24}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3} Behavioral form MMD}{25}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4} Closed-form vs Behavioral-form}{26}{subsection.3.3.4}%
\contentsline {subsection}{\numberline {3.3.5} Comparison of MMD to other Mirror Decent based methods}{27}{subsection.3.3.5}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {4\hskip 2em}\uppercase {Modified Updates for Last-iterate Convergence}}{28}{chapter.4}%
\contentsline {section}{\numberline {4.1} Neural Replicator Dynamics (NeuRD)}{29}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1} Replicator Dynamics and No-regret Learning}{29}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2} NeuRD}{30}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3} Relation to Natural Policy Gradients}{31}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4} Alternating vs Simultaneous gradient updates}{31}{subsection.4.1.4}%
\contentsline {section}{\numberline {4.2} Extragradient and Optimistic Gradient}{32}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1} Extragradient (EG)}{32}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2} Optimistic gradient (OPT)}{33}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3} Optimistic Mirror Descent}{34}{subsection.4.2.3}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {5\hskip 2em}\uppercase {Tabular Experiments}}{36}{chapter.5}%
\contentsline {section}{\numberline {5.1} Experimental Domains}{36}{section.5.1}%
\contentsline {section}{\numberline {5.2} Evaluation Metrics}{37}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1} Divergence to the equilibrium}{38}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2} Exploitability}{38}{subsection.5.2.2}%
\contentsline {section}{\numberline {5.3} Experiment Setup}{38}{section.5.3}%
\contentsline {section}{\numberline {5.4} Results}{39}{section.5.4}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {6\hskip 2em}\uppercase {Deep Multi-Agent RL Experiments}}{44}{chapter.6}%
\contentsline {section}{\numberline {6.1} Experimental Domains}{44}{section.6.1}%
\contentsline {section}{\numberline {6.2} Evaluation Metrics}{45}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1} Approximate Exploitability}{45}{subsection.6.2.1}%
\contentsline {section}{\numberline {6.3} Experiment Setup}{45}{section.6.3}%
\contentsline {section}{\numberline {6.4} Results}{46}{section.6.4}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {7\hskip 2em}\uppercase {Discussion}}{49}{chapter.7}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {8\hskip 2em}\uppercase {Conclusion}}{51}{chapter.8}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {\ }APPENDICES}{52}{chapter.8}%
\contentsline {chapter}{\xnumberline {\ }\ \ \ \ \ Appendix A}{53}{appendix.A}%
\contentsline {chapter}{\xnumberline {\ }\ \ \ \ \ Appendix B}{54}{appendix.B}%
\addvspace {\baselineskip }
\contentsline {chapter}{\xnumberline {\ }CITED LITERATURE}{55}{appendix.B}%
